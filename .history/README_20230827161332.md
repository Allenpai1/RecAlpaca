# Beyond GPT-3.5 in Conversational Recommendation Systems: Introducing RecAlpaca, a Fine-tuned Model based on Alpaca-7B

<br />

This is the project code which aim to build a dedicated instruction following dataset that not only facilitates the fine-tuning of a language model for explainable recommendations but also a strong recommendation capabilities.

This repo contains:
- The code to generate the data.
- The code to fine-tuning Alpaca-7B.
- The code to evaluate Alpaca-7B.

## Overview

The RecAlpaca model is a result of fine-tuning a 7B Alpaca model [1] using a dataset consisting of 13k examples of instruction recommendations. These recommendations were generated following the approach described in a research paper referred to as Self-Instruct [2]. The weights of RecAlpaca can be found in HuggingFace Hub with [model card](https://huggingface.co/Allenpai/AlpacaLoraRec).

[1]: Alpaca: Stanford Alpaca: An Instruction-following LLaMA model. Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto. https://github.com/tatsu-lab/stanford_alpaca

[2]: Self-Instruct: Aligning Language Model with Self Generated Instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi. https://arxiv.org/abs/2212.10560

## Data Release

The file [`rec_combined_data.json`](./trainingSet/rec_combined_data.json) is a dataset containing 13k instances of instruction-following data used for fine-tuning the RecAlpaca model. This JSON file is structured as a list of dictionaries, where each dictionary contains the following information:

- `instruction`: A string describing the recommendation tasks and their respective domains.
- `input`: A string representing the input, which can either be the highly rated items of the user or a combination of the user's profile and items they like & dislike.
- `output`: A string indicating the generated recommendation items and the reasons for those recommendations. This output is generated using the `gpt3.5-turbo`.

The file [`ML100kEvaluationRecAlpaca.json`](./testSet/ML100kEvaluationRecAlpaca.json) serves as a test set and includes 200 samples that have been randomly selected from the [MovieLens-100k](https://grouplens.org/datasets/movielens/100k/) Dataset. These samples are structured similarly to what was previously described. However, they contain additional information:

- `testGT`: testset ground truth which comprises a randomly selected 20% of movies that the user truly enjoyed and preferred.
- `output`: consists of the recommendation results produced by the RecAlpaca model, excluding the top1 recommended movie in the input prompt.
- `wTop1Input`: contains input prompts alongside the top1 recommended movie.
-  `output2`:  holds the recommendation outcomes from the RecAlpaca model, including the top1 recommended movie from the input prompts.

## Experiments Environments
 - OS: Intel(R) Core(TM) i5-8259U@230 GHz Macbook pro 2020
 - GPU:NVIDIA GeForce RTX 3090 with 24GB RAM

## Install requirements
 - ```pip install -r requirements.txt```

## RecAlpaca vs Alpaca-7B

### On recommendation task:

In the context of the recommendation task, the input prompts encompass details about user profiles, movies that are highly preferred by the user, movies that have lower preference, candidate set generate from a classical recommendation system (lightGCN) and the outcome of the top1 recommended choice.

 ![plot](./imgs/Flowchart.jpg) 

 Figure above illustrates a comparsion between generation outputs from the test set using Alpaca and RecAlpaca. The difference are notable: without any fine-tuning, the Alpaca model tends to prioritize recommendations that fill the first four positions of the candidate set. This happens without accounting for the user's profile or preferences, and without providing any explanation for the recommendations.

 In contrast, RecAlpaca enhances its recommendations by incorporating comprehensive movie details and explaining the reasons behind each recommendation. It achieves this by taking into consideration the user's specific details and preferences during the recommendation process.

### On general query:

When it comes to queries involving suggestions or recommendations, the RecAlpaca model has a tendency to offer outputs that are more comprehensible and well-structured. An example illustrating this can be seen in the figure provided below:

 ![plot](./imgs/Flowchart2.jpg) 

 

## RecAlpaca vs GPT3.5

| Models | LLaMA-7B | LLaMA-13B |
|----------------|----------|-----------|
| Batch size     | 128      | 128       |
| Learning rate  | 2e-5     | 1e-5      |
| Epochs         | 3        | 5         |
| Max length     | 512      | 512       |
| Weight decay   | 0        | 0         |

## Usage and run
The code under the folder System code is already defined and ready to use, where the main.py is the system connected with the camera and QA_results.pdf is the returning pdf results; it will get updated once you run.

To run the program you can download my pretrained model on [google drive](https://drive.google.com/drive/folders/1bBdFgyOmAyaZJotF_79pKl8VIXhYggee?usp=sharing) and put it in System\ code/logs folder and in the main.py program you need to generate a personal [ChatGPT-API key](https://openai.com/blog/introducing-chatgpt-and-whisper-apis) :
```
 cd System\ code/
 python main.py
```
When the camera is launched, press the ```space``` keyword to take the photo and ```q``` to quit the system.
The system will return the intermediate results, the results will be similar as following:
 1. For Faster-RCNN text language detection:
 
 ![plot](./Images/combine.png)

 2. PaddleOCR text extraction results:
 ![plot](./Images/paddleChinese.png)
 ![plot](./Images/paddleEnglish.png)

 3. QA results in PDF:
 ![plot](./Images/ChineseDoc.png)
 ![plot](./Images/EnglishDoc.png)

 ## Train you own model
Ensure the dataset is in the correct VOC format and put it into the folder PyTorch train F-RCNN and run ```python train.py``` and you need to change your own model_data/classes.txt. It would be beneficial to understand how the network architecture is written by looking at the source code I have included. The source codes are collected from [faster-rcnn-pytorch](https://github.com/bubbliiiing/faster-rcnn-pytorch) and [tensorflow-faster-rcnn](https://github.com/endernewton/tf-faster-rcnn).
![plot](./Images/FRCNN.png)
